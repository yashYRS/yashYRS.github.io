

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>Yash Sarrof</title>
  <subtitle>Research Assistant working with Dr. Michael Hahn in LaCoCo Lab, Saarland University. I am interested in the interpretability of models both from a mechanistic viewpoint and by using formal methods to enhance our understanding of these models.</subtitle>
  <updated>2025-01-25T16:24:18+01:00</updated>
  <author>
    <name>Yash Sarrof</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator>
  <rights> © 2025 Yash Sarrof </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Lost before Translation: Examining Language Death</title>
    <link href="http://localhost:4000/posts/LanguageDeath/" rel="alternate" type="text/html" title="Lost before Translation: Examining Language Death" />
    <published>2024-10-07T00:00:00+02:00</published>
  
    <updated>2024-10-07T00:00:00+02:00</updated>
  
    <id>http://localhost:4000/posts/LanguageDeath/</id>
    <content src="http://localhost:4000/posts/LanguageDeath/" />
    <author>
      <name>Yash Sarrof</name>
    </author>

  
    
  

  <summary>August Schleicher’s Stammbaum Theory of Linguistic Change, introduced in 1871, proposes that the evolution of languages follows a predictable pattern. According to this theory, similarities between languages are akin to genetic relationships, which allows for organizing languages into a tree-like structure, showing how they have diverged and evolved from common ancestors. While this theory prov...</summary>

  </entry>

  
  <entry>
    <title>Getting Started with Table Extraction in Document AI</title>
    <link href="http://localhost:4000/posts/TableContentExtraction/" rel="alternate" type="text/html" title="Getting Started with Table Extraction in Document AI" />
    <published>2021-09-01T00:00:00+02:00</published>
  
    <updated>2021-09-01T00:00:00+02:00</updated>
  
    <id>http://localhost:4000/posts/TableContentExtraction/</id>
    <content src="http://localhost:4000/posts/TableContentExtraction/" />
    <author>
      <name>Yash Sarrof</name>
    </author>

  
    
  

  <summary>Table extraction fall under the umbrella of Document Intelligence, a relatively new research topic that deals with analzying and understanding business documents. The documents vary in style, layouts, fonts and generally have a complex template. Since digitisation of documents is a recent phenonmenon, majority of such documents are scanned copies of their printed counterparts. The poor quality ...</summary>

  </entry>

  
  <entry>
    <title>SAdam: An Adam variant that converges faster for convex loss functions</title>
    <link href="http://localhost:4000/posts/SadamOptimizer/" rel="alternate" type="text/html" title="SAdam: An Adam variant that converges faster for convex loss functions" />
    <published>2021-03-29T00:00:00+02:00</published>
  
    <updated>2021-03-29T00:00:00+02:00</updated>
  
    <id>http://localhost:4000/posts/SadamOptimizer/</id>
    <content src="http://localhost:4000/posts/SadamOptimizer/" />
    <author>
      <name>Yash Sarrof</name>
    </author>

  
    
  

  <summary>SAdam (Wang et al, 2019) is an online convex optimizer that enhances the Adam algorithm by utilizing strong convexity of functions wherever possible. Although the motivation behind making these modifications are to improve performance in only convex cases, they prove to be effective even in non-convex cases. I undertook this project along with Narayanan ER as part of the ML Reproducibility Chal...</summary>

  </entry>

  
  <entry>
    <title>Agony, expectation, relief &amp; the journey in between</title>
    <link href="http://localhost:4000/posts/Hopeless/" rel="alternate" type="text/html" title="Agony, expectation, relief &amp;amp; the journey in between" />
    <published>2020-12-18T00:00:00+01:00</published>
  
    <updated>2020-12-18T00:00:00+01:00</updated>
  
    <id>http://localhost:4000/posts/Hopeless/</id>
    <content src="http://localhost:4000/posts/Hopeless/" />
    <author>
      <name>Yash Sarrof</name>
    </author>

  
    
  

  <summary>Somewhere in the middle of February 2020, I was moving into my first rented house. The place was perfect, it was isolated enough from the main roads to be quite and sombre at night, whilst also being a 10 minute walk from the Samsung R&amp;amp;amp;D Bangalore Campus where I was interning. The internship stipend was healthy, and so life in the city was pretty exciting. Weekend get togethers, making my o...</summary>

  </entry>

  
  <entry>
    <title>My Personal Productivity Hacks: Open Source Tools for the Adventurous Linux User</title>
    <link href="http://localhost:4000/posts/LinuxTools/" rel="alternate" type="text/html" title="My Personal Productivity Hacks: Open Source Tools for the Adventurous Linux User" />
    <published>2020-10-10T00:00:00+02:00</published>
  
    <updated>2020-10-10T00:00:00+02:00</updated>
  
    <id>http://localhost:4000/posts/LinuxTools/</id>
    <content src="http://localhost:4000/posts/LinuxTools/" />
    <author>
      <name>Yash Sarrof</name>
    </author>

  
    
  

  <summary>As a Computer Science engineer every miniscule jump in productivity in and around the workspace tends to have a butterfly effect, and ends up being a huge time savior. Over the years, I have disovered a few open source programs that have had a similar effect for me, and despite a oblique learning curve for most of them, they have become indispensible aspects of my working environment. It should...</summary>

  </entry>

</feed>


